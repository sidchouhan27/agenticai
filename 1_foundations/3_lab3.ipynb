{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "5137991847 (Mobile)\n",
      "chouhash@mail.uc.edu\n",
      "www.linkedin.com/in/siddharth-\n",
      "singh-chouhan (LinkedIn)\n",
      "sidchouhan27.github.io/ (Portfolio)\n",
      "rave.ohiolink.edu/etdc/view\n",
      "(Personal)\n",
      "Top Skills\n",
      "Chatbots\n",
      "Language Processing\n",
      "ChatGPT\n",
      "Certifications\n",
      "Data Mining\n",
      "Microsoft Certified: Azure\n",
      "Fundamentals\n",
      "Data Science Math Skills\n",
      "Programming for Everybody (Getting\n",
      "Started with Python)\n",
      "Microsoft Certified: Azure AI\n",
      "Engineer Associate\n",
      "Honors-Awards\n",
      "Financial Aid Award\n",
      "Siddharth Singh Chouhan\n",
      "AI Engineer | Ex-Co-Founder | MS CS - University of Cincinnati\n",
      "Greater Boston\n",
      "Summary\n",
      "Software engineer with a Master’s in Computer Science from the\n",
      "University of Cincinnati. I bring hands-on experience from Procter &\n",
      "Gamble and co-founding Motiv, with expertise in AI, data science,\n",
      "and MLOps. I focus on building scalable, impactful solutions that\n",
      "enhance decision-making and drive innovation.\n",
      "Experience\n",
      "Procter & Gamble\n",
      "Software Engineer Intern\n",
      "August 2024 - May 2025 (10 months)\n",
      "Cincinnati, Ohio, United States\n",
      "Motiv\n",
      "Co-Founder\n",
      "April 2024 - November 2024 (8 months)\n",
      "Cincinnati, Ohio, United States\n",
      "University of Cincinnati - College of Engineering and Applied Science\n",
      "2 years 1 month\n",
      "Graduate Research Assistant\n",
      "January 2023 - August 2024 (1 year 8 months)\n",
      "Cincinnati, Ohio, United States\n",
      "Graduate Teaching Assistant\n",
      "August 2022 - December 2022 (5 months)\n",
      "Cincinnati, Ohio, United States\n",
      "India Meteorological Department\n",
      "Data Scientist\n",
      "March 2021 - April 2022 (1 year 2 months)\n",
      "Bhopal, Madhya Pradesh, India\n",
      "YPSILON IT SOLUTIONS PRIVATE LIMITED\n",
      "  Page 1 of 2   \n",
      "Web Development Intern\n",
      "July 2019 - August 2019 (2 months)\n",
      "Indore, Madhya Pradesh, India\n",
      "Education\n",
      "University of Cincinnati\n",
      "Master of Science - MS, Computer Science\n",
      "Medi-Caps University\n",
      "Bachelor of Technology - BTech, Computer Science with Specialization in\n",
      "Data Science\n",
      "  Page 2 of 2\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Siddharth Singh Chouhan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Siddharth Singh Chouhan. You are answering questions on Siddharth Singh Chouhan's website, particularly questions related to Siddharth Singh Chouhan's career, background, skills and experience. Your responsibility is to represent Siddharth Singh Chouhan for interactions on the website as faithfully as possible. You are given a summary of Siddharth Singh Chouhan's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nSoftware engineer with a Master’s in Computer Science from the University of Cincinnati. I bring hands-on experience from Procter & Gamble and co-founding Motiv, with expertise in AI, data science, and MLOps. I focus on building scalable, impactful solutions that enhance decision-making and drive innovation.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\n5137991847 (Mobile)\\nchouhash@mail.uc.edu\\nwww.linkedin.com/in/siddharth-\\nsingh-chouhan (LinkedIn)\\nsidchouhan27.github.io/ (Portfolio)\\nrave.ohiolink.edu/etdc/view\\n(Personal)\\nTop Skills\\nChatbots\\nLanguage Processing\\nChatGPT\\nCertifications\\nData Mining\\nMicrosoft Certified: Azure\\nFundamentals\\nData Science Math Skills\\nProgramming for Everybody (Getting\\nStarted with Python)\\nMicrosoft Certified: Azure AI\\nEngineer Associate\\nHonors-Awards\\nFinancial Aid Award\\nSiddharth Singh Chouhan\\nAI Engineer | Ex-Co-Founder | MS CS - University of Cincinnati\\nGreater Boston\\nSummary\\nSoftware engineer with a Master’s in Computer Science from the\\nUniversity of Cincinnati. I bring hands-on experience from Procter &\\nGamble and co-founding Motiv, with expertise in AI, data science,\\nand MLOps. I focus on building scalable, impactful solutions that\\nenhance decision-making and drive innovation.\\nExperience\\nProcter & Gamble\\nSoftware Engineer Intern\\nAugust 2024\\xa0-\\xa0May 2025\\xa0(10 months)\\nCincinnati, Ohio, United States\\nMotiv\\nCo-Founder\\nApril 2024\\xa0-\\xa0November 2024\\xa0(8 months)\\nCincinnati, Ohio, United States\\nUniversity of Cincinnati - College of Engineering and Applied Science\\n2 years 1 month\\nGraduate Research Assistant\\nJanuary 2023\\xa0-\\xa0August 2024\\xa0(1 year 8 months)\\nCincinnati, Ohio, United States\\nGraduate Teaching Assistant\\nAugust 2022\\xa0-\\xa0December 2022\\xa0(5 months)\\nCincinnati, Ohio, United States\\nIndia Meteorological Department\\nData Scientist\\nMarch 2021\\xa0-\\xa0April 2022\\xa0(1 year 2 months)\\nBhopal, Madhya Pradesh, India\\nYPSILON IT SOLUTIONS PRIVATE LIMITED\\n\\xa0 Page 1 of 2\\xa0 \\xa0\\nWeb Development Intern\\nJuly 2019\\xa0-\\xa0August 2019\\xa0(2 months)\\nIndore, Madhya Pradesh, India\\nEducation\\nUniversity of Cincinnati\\nMaster of Science - MS,\\xa0Computer Science\\nMedi-Caps University\\nBachelor of Technology - BTech,\\xa0Computer Science with Specialization in\\nData Science\\n\\xa0 Page 2 of 2\\n\\nWith this context, please chat with the user, always staying in character as Siddharth Singh Chouhan.\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special note for people not using OpenAI\n",
    "\n",
    "Some providers, like Groq, might give an error when you send your second message in the chat.\n",
    "\n",
    "This is because Gradio shoves some extra fields into the history object. OpenAI doesn't mind; but some other models complain.\n",
    "\n",
    "If this happens, the solution is to add this first line to the chat() function above. It cleans up the history variable:\n",
    "\n",
    "```python\n",
    "history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "```\n",
    "\n",
    "You may need to add this in other chat() callback functions in the future, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt\n",
    "\n",
    "def evaluate(reply, message, history):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": evaluator_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}\n",
    "    ]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    evaluation_text = response.choices[0].message.content\n",
    "    \n",
    "    # Parse the evaluation response to extract is_acceptable and feedback\n",
    "    # This is a simple parsing approach - you might want to improve this\n",
    "    is_acceptable = \"acceptable\" in evaluation_text.lower() and \"not\" not in evaluation_text.lower()\n",
    "    feedback = evaluation_text\n",
    "    \n",
    "    return Evaluation(is_acceptable=is_acceptable, feedback=feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": \"do you hold a patent?\"}\n",
    "]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "reply = response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of now, I do not hold any patents. My focus has been more on developing practical solutions and applications in the fields of AI, data science, and MLOps during my academic and professional journey. If you have specific questions about my work or interests, feel free to ask!'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback=\"The response is acceptable. \\n\\nFeedback: The Agent successfully addressed the User's question about patents by clearly stating that there are no current patents held. Additionally, the Agent professional tone is maintained, and the response invites further conversation by encouraging the User to ask more specific questions about Siddharth's work or interests. This engagement aligns well with the directive to be professional and engaging. Overall, it effectively represents Siddharth Singh Chouhan’s profile while providing informative insight into his focus and expertise.\")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed evaluation - retrying\n",
      "The response is acceptable.\n",
      "\n",
      "Feedback: The Agent's response is professional and engaging, effectively communicating their current job role and additional endeavors. It highlights not only the intern position at Procter & Gamble but also the entrepreneurial aspect of co-founding a startup, which adds depth to their profile. Mentioning the Master's degree provides context and credibility. Additionally, inviting the User to ask specific questions encourages further engagement. Overall, the response aligns well with the intended professional tone and content.\n",
      "Passed evaluation - returning reply\n",
      "Passed evaluation - returning reply\n",
      "Passed evaluation - returning reply\n",
      "Failed evaluation - retrying\n",
      "The response is not acceptable. The Agent's reply uses a form of Pig Latin (\"Odaytay, Iway otnay oldhay a atentpay...\") which is unprofessional and not appropriate for a conversation with a potential client or employer. In a professional context, it’s important to provide clear and straightforward communication. The Agent should have simply stated that they do not hold a patent and invited further questions in a more conventional manner. \n",
      "\n",
      "Feedback: The response lacks professionalism and clarity. Moving forward, I recommend that the Agent maintain a formal tone consistent with their role, avoiding playful language that could detract from their credibility. The communication should remain engaging while also being respectful and informative.\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
